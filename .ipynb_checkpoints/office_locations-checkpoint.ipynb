{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Office Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://about.google/locations/?region=true'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all(\"div\", class_= \"office-info\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all(\"div\", class_= \"office-info\")\n",
    "for result in results:\n",
    "    office = result.find(\"h2\", itemprop= \"name\").text\n",
    "    address = result.find(\"div\",itemprop= \"address\").text\n",
    "    quards = result.find(\"a\")['href']\n",
    "    print(\"-------------------\")\n",
    "    print(office, address, quards)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "addresses = []\n",
    "quardss = []\n",
    "\n",
    "for result in results:\n",
    "    office = result.find(\"h2\", class_= \"office-name\").text\n",
    "    address = result.find(\"div\", class_= \"office-address\").text\n",
    "    quards = result.find(\"a\")['href']\n",
    "    location.append(office)\n",
    "    addresses.append(address)\n",
    "    quardss.append(quards)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the parsed data above\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Office\": location,\n",
    "    \"Address\": addresses,\n",
    "    \"Quards\": quardss\n",
    "})\n",
    "\n",
    "# Removes all occurances of \"\\n\"\n",
    "df[\"Office\"].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True) \n",
    "df[\"Address\"].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True) \n",
    "\n",
    "#Drops the:'https://www.google.com/maps/dir/Current+Location/ at the beggining of the string\n",
    "# and the: ?hl=en at the end of the string\n",
    "df[\"Quards2\"]= df[\"Quards\"].str.strip('https://www.google.com/maps/dir/Current+Location/ ?hl=en')\n",
    "\n",
    "# Drops the old Column with the google hyperlinks\n",
    "df = df.drop(columns=['Quards'])\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "new = df[\"Quards2\"].str.split(\",\", n = 1, expand = True) \n",
    "  \n",
    "# making separate Latitude column from new data frame \n",
    "df[\"Latitude\"]= new[0] \n",
    "  \n",
    "# making separate Longitude column from new data frame \n",
    "df[\"Longitude\"]= new[1] \n",
    "  \n",
    "# Dropping old Quards2 columns \n",
    "df.drop(columns =[\"Quards2\"], inplace = True) \n",
    "  \n",
    "# Drops duplicates and only keeps the Office's first occurance\n",
    "df= df.drop_duplicates(subset=[\"Office\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Company\"] = (\"Google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Office Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': \"chromedriver.exe\"}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pg_nums = ('1', '2', '3', '4', '5', '6', '7', '8')\n",
    "\n",
    "url='https://craft.co/amazon/locations?page=1'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver=webdriver.Chrome('C:/Users/sara.hovakeemian/Documents/Python Scripts/chromedriver.exe',\n",
    "                 chrome_options=webdriver.ChromeOptions().add_argument(\"--disable-notifications\"))\n",
    "for i in pg_nums (2, 9):\n",
    "    url_visit=url[:-1]+str(i)\n",
    "    driver.get(url_visit)\n",
    "    try:\n",
    "        driver.find_element_by_class_name('craft-modal_close_button').click()\n",
    "        soup=BeautifulSoup(driver.page_source, 'lxml')\n",
    "        locations=soup.find_all('div', class_='location')\n",
    "        driver.find_element_by_class_name('craft-modal_close_button').click()\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "offices = []\n",
    "addresses = []\n",
    "countries = []\n",
    "\n",
    "\n",
    "\n",
    "url='https://craft.co/amazon/locations?page=1'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver=webdriver.Chrome('chromedriver.exe',\n",
    "                 chrome_options=webdriver.ChromeOptions().add_argument(\"--disable-notifications\"))\n",
    "for i in range (2, 9):\n",
    "    url_visit=url[:-1]+str(i)\n",
    "    driver.get(url_visit)\n",
    "    try:\n",
    "        driver.find_element_by_class_name('craft-modal_close_button').click()\n",
    "        soup=BeautifulSoup(driver.page_source, 'lxml')\n",
    "        locations=soup.find_all(\"div\", class_= \"location\")\n",
    "        for amazonresult in locations:\n",
    "            office = amazonresult.find(itemprop= \"addressLocality\").text\n",
    "            address = amazonresult.find(itemprop= \"streetAddress\")\n",
    "            state = amazonresult.find(class_=\"location__state\")\n",
    "            country = amazonresult.find(class_=\"location__country\")\n",
    "            print(office)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'office' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-490a8fd89e4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'office' is not defined"
     ]
    }
   ],
   "source": [
    "print(office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonurl='https://craft.co/amazon/locations?page='\n",
    "pg_num = ['2', '3', '4', '5', '6', '7', '8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'click'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9a24809daacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mamazonsoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamazonsoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"auth-form__link\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2079\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 2081\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'click'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "amazonsoup = bs(html, \"html.parser\")\n",
    "a = amazonsoup.find_all(\"a\", class_ = \"auth-form__link\")\n",
    "a.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amazonsoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-36cb9c76e726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mqueryamazonurl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamazonurl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamazonurl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mamazonresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamazonsoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"location\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mamazonresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mamazonresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0moffice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamazonresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemprop\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"addressLocality\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'amazonsoup' is not defined"
     ]
    }
   ],
   "source": [
    "for num in pg_num:\n",
    "    queryamazonurl = browser.visit(amazonurl + '2')\n",
    "    browser.visit(amazonurl)\n",
    "    amazonresults = amazonsoup.find_all(\"div\", class_= \"location\")\n",
    "    for amazonresult in amazonresults:\n",
    "            office = amazonresult.find(\"span\", itemprop= \"addressLocality\").text\n",
    "            address = amazonresult.find(\"span\",itemprop= \"streetAddress\")\n",
    "            country = amazonresult.find(\"div\", class_=\"location_country\")\n",
    "            print(\"-------------------\")\n",
    "            print(num, office, address, country)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazonsoup = bs(html, \"html.parser\")\n",
    "print(amazonsoup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in pg_num:\n",
    "    amazonresults = amazonsoup.find_all('div', itemprop=\"location\")\n",
    "    for amazonresult in amazonresults:\n",
    "        office = amazonresult.find(itemprop= \"addressLocality\").text\n",
    "        address = amazonresult.find(itemprop=\"streetAddress\").text\n",
    "        state = amazonresult.find(class_=\"location__state\").text\n",
    "        country = amazonresult.find(class_=\"location__country\").text\n",
    "        print(\"-------------------\")\n",
    "        print(num, office, address, state, country)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
